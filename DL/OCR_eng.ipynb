{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trdg.generators import (\n",
    "    GeneratorFromDict,\n",
    "    GeneratorFromRandom,\n",
    "    GeneratorFromStrings,\n",
    "    GeneratorFromWikipedia,\n",
    ")\n",
    "from random import sample\n",
    "from itertools import combinations, permutations\n",
    "\n",
    "\n",
    "folder = '/Users/liuliangjun/Downloads/images/vaild'\n",
    "\n",
    "ss = '0123456789 '\n",
    "_len_8 = [i for i in map(lambda x: ''.join(x), permutations(ss, 8))]\n",
    "_len_7 = [i for i in map(lambda x: ''.join(x), permutations(ss, 7))]\n",
    "_len_7 = [i for i in map(lambda x: ''.join(x), permutations(ss, 7))]\n",
    "_len_6 = [i for i in map(lambda x: ''.join(x), permutations(ss, 6))]\n",
    "_len_5 = [i for i in map(lambda x: ''.join(x), permutations(ss, 5))]\n",
    "_len_4 = [i for i in map(lambda x: ''.join(x), permutations(ss, 4))]\n",
    "_len_3 = [i for i in map(lambda x: ''.join(x), permutations(ss, 3))]\n",
    "_len_2 = [i for i in map(lambda x: ''.join(x), permutations(ss, 2))]\n",
    "\n",
    "\n",
    "lst = [*sample(_len_6, 200), *sample(_len_7, 200), *sample(_len_8, 200)]\n",
    "# lst = [*_len_2, *sample(_len_3, 300), *sample(_len_4, 500), *sample(_len_6, 800), *sample(_len_7, 1000)]\n",
    "# lst = sample(_len_5, 20)\n",
    "lst = [i.strip() for i in lst]\n",
    "print(len(lst))\n",
    "\n",
    "\n",
    "generator = GeneratorFromStrings(lst, width=150, count=len(lst))\n",
    "\n",
    "count = 0\n",
    "\n",
    "for img, lbl in generator:\n",
    "    img.save(os.path.join(folder, f'{count}_{lbl}.png'))\n",
    "    count += 1\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alphabet = u'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ~!@#$%^&*?-_+=()[]{}/|\\<>,.;:\\'\" '\n",
    "alphabet = '0123456789 '\n",
    "len(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import cv2\n",
    "import random\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "def text_to_labels(text,alphabet):\n",
    "    ret = []\n",
    "    for char in text:\n",
    "        ret.append(alphabet.find(char))\n",
    "    return ret\n",
    "\n",
    "def loadpic(path,batchSize,absolute_max_string_len,downsample_factor):\n",
    "    imgPaths=list(paths.list_images(path))\n",
    "    random.shuffle(imgPaths) \n",
    "    print(len(imgPaths))\n",
    "    random.seed(20)\n",
    "\n",
    "    while 1:\n",
    "        x_batch=[]#图片\n",
    "        flag = False\n",
    "        y_batch=np.ones([batchSize, absolute_max_string_len]) * -1 # 图片标签变成编码\n",
    "        input_length = np.zeros([batchSize, 1]) # 图片下采样后进入GRN的尺寸\n",
    "        label_length=np.zeros([batchSize, 1]) # 图片中字符的长度\n",
    "        labels_batch=[] # 图片的真是标签 字符串\n",
    "        for i in range(batchSize):\n",
    "\n",
    "            imgpath=imgPaths[random.randint(0,len(imgPaths)-1)]\n",
    "            # print(imgpath)\n",
    "            try:\n",
    "                img=cv2.imread(imgpath,0)\n",
    "                img=cv2.resize(img,(150,32))\n",
    "            except:\n",
    "                print(imgpath)\n",
    "                flag = True\n",
    "                break\n",
    "            \n",
    "            # cv2.imshow(\"ig\",img)\n",
    "            # cv2.waitKey(30)\n",
    "            img=img_to_array(img)\n",
    "            x_batch.append(img)\n",
    "            \n",
    "            input_length[i]=np.array(img).shape[1]//downsample_factor\n",
    "\n",
    "            # imgname=imgpath[imgpath.rindex('\\\\')+1:imgpath.rindex('.')]\n",
    "            imgname=imgpath.split('_')[-1].split('.')[0]\n",
    "            labels_batch.append(imgname)\n",
    "\n",
    "            label_length[i]=len(imgname)\n",
    "\n",
    "            y_batch[i,0:len(imgname)]=text_to_labels(imgname, alphabet)\n",
    "\n",
    "        if flag:\n",
    "            flag = False\n",
    "            continue\n",
    "\n",
    "        x_batch = np.array(x_batch, dtype=\"float\") / 255.0 - 0.5\n",
    "#         x_batch= x_batch.swapaxes(1,2)\n",
    "\n",
    "        inputs = {'the_input': x_batch,\n",
    "                  'the_labels': y_batch,\n",
    "                  'input_length': input_length,\n",
    "                  'label_length': label_length,\n",
    "                  'source_str': labels_batch  # used for visualization only # 可视化使用\n",
    "                  }\n",
    "        outputs = {'ctc': np.zeros([batchSize])}  \n",
    "        yield (inputs,outputs)\n",
    "        \n",
    "# https://github.com/felixBrave/ocr_chinese/blob/master/crnn/net/training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Dropout\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import GRU\n",
    "\n",
    "\n",
    "class OCRNet:\n",
    "    @staticmethod\n",
    "    def ctc_lambda_func(args):\n",
    "        y_pred, labels, input_length, label_length = args\n",
    "        # 注意这里若使用y_pred会导致sequence_length（0）<= X.\n",
    "        # 注意理解sequence_length(0)这个东西  这里是32  因为第41句中的img_w//poolsize（2）是sequence_length（0）\n",
    "        y_pred = y_pred[:, :, :]\n",
    "        # 这里labels是实际的标签，y_pred是预测出来的标签，input_length是预测标签的长度，label_length是实际标签的长度\n",
    "        return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "    @staticmethod\n",
    "    def build(img_w, img_h, depth, alphabetLength, absolute_max_string_len):\n",
    "        conv_filters = 32  \n",
    "        kernel_size = (3, 3)\n",
    "        pool_size = (2, 2)\n",
    "        time_dense_size = 128\n",
    "        rnn_size = 128  \n",
    "\n",
    "        act = 'relu'\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            input_shape = (depth, img_w, img_h)\n",
    "        else:\n",
    "            input_shape = (img_w, img_h, depth)\n",
    "\n",
    "        input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "        \n",
    "        # 参考VGG19网络，双层卷积层再接一层池化层\n",
    "        \n",
    "        inner = Conv2D(conv_filters, kernel_size, padding='same', activation=act, name='conv1')(input_data)\n",
    "        inner = Conv2D(conv_filters, kernel_size, padding='same', activation=act,  name='conv2')(inner)\n",
    "        inner = BatchNormalization()(inner)\n",
    "        inner = MaxPooling2D(pool_size=pool_size, name='max1')(inner)\n",
    "\n",
    "        inner = Conv2D(conv_filters*2, kernel_size, padding='same', activation=act, name='conv3')(inner)\n",
    "        inner = Conv2D(conv_filters*2, kernel_size, padding='same', activation=act, name='conv4')(inner)\n",
    "        inner = BatchNormalization()(inner)\n",
    "        inner = MaxPooling2D(pool_size=pool_size, name='max2')(inner)\n",
    "\n",
    "        inner = Conv2D(conv_filters*4, kernel_size, padding='same', activation=act, name='conv5')(inner)\n",
    "        inner = Conv2D(conv_filters*4, kernel_size, padding='same', activation=act, name='conv6')(inner)\n",
    "        inner = BatchNormalization()(inner)\n",
    "        inner = MaxPooling2D(pool_size=pool_size, name='max3')(inner)\n",
    "        \n",
    "        inner = Conv2D(conv_filters*4, kernel_size, padding='same', activation=act, name='conv7')(inner)\n",
    "        inner = Conv2D(conv_filters*4, kernel_size, padding='same', activation=act, name='conv8')(inner)\n",
    "        inner = BatchNormalization()(inner)\n",
    "        inner = MaxPooling2D(pool_size=pool_size, name='max4')(inner)\n",
    "        \n",
    "        conv_to_rnn_dims = (img_w // (pool_size[0] ** 4), (img_h // (pool_size[0] ** 4)) * conv_filters*4)\n",
    "        inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "        inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "        gru_1 = GRU(rnn_size, return_sequences=True,\n",
    "                    kernel_initializer='he_normal', name='gru1')(inner)\n",
    "        gru_1b = GRU(rnn_size, return_sequences=True,\n",
    "                     go_backwards=True, kernel_initializer='he_normal',\n",
    "                     name='gru1_b')(inner)\n",
    "        gru1_merged = add([gru_1, gru_1b])\n",
    "\n",
    "        gru_2 = GRU(rnn_size, return_sequences=True,\n",
    "                    kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "        gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True,\n",
    "                     kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "        \n",
    "        # 多添加一层Dense\n",
    "        inner = Dropout(0.5)(concatenate([gru_2, gru_2b]))\n",
    "        inner = Dense(256, name='dense2')(inner)\n",
    "\n",
    "        # transforms RNN output to character activations:\n",
    "        # 是len(alphabet)+1 还是 len(alphabet) 为何？？？\n",
    "        inner = Dense(len(alphabet), name='dense3')(inner)\n",
    "        y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "        base_model = Model(inputs=input_data, outputs=y_pred)\n",
    "        # base_model.summary()\n",
    "\n",
    "        labels = Input(name='the_labels', shape=[absolute_max_string_len], dtype='float32')\n",
    "        input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "        label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "        loss_out = Lambda(OCRNet.ctc_lambda_func, output_shape=(1,), name='ctc')(\n",
    "            [y_pred, labels, input_length, label_length])\n",
    "\n",
    "        train_model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "        train_model.summary()\n",
    "        return base_model, train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 280, 32, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 280, 32, 32)  320         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 280, 32, 32)  9248        conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 280, 32, 32)  128         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 140, 16, 32)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 140, 16, 64)  18496       max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 140, 16, 64)  36928       conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 140, 16, 64)  256         conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 70, 8, 64)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 70, 8, 128)   73856       max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 70, 8, 128)   147584      conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 70, 8, 128)   512         conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max3 (MaxPooling2D)             (None, 35, 4, 128)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 35, 4, 128)   147584      max3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv8 (Conv2D)                  (None, 35, 4, 128)   147584      conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 4, 128)   512         conv8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max4 (MaxPooling2D)             (None, 17, 2, 128)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 17, 256)      0           max4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 17, 128)      32896       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 17, 128)      98688       dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru1_b (GRU)                    (None, 17, 128)      98688       dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 17, 128)      0           gru1[0][0]                       \n",
      "                                                                 gru1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 17, 128)      98688       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2_b (GRU)                    (None, 17, 128)      98688       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 17, 256)      0           gru2[0][0]                       \n",
      "                                                                 gru2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 17, 256)      0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 17, 256)      65792       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense3 (Dense)                  (None, 17, 94)       24158       dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 17, 94)       0           dense3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, 36)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,100,606\n",
      "Trainable params: 1,099,902\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "absolute_max_string_len = 36\n",
    "base_model, train_model = OCRNet.build(280, 32, 1, len(alphabet), absolute_max_string_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 是\n",
    "\n",
    "import os,sys\n",
    "# parentdir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "# sys.path.append(parentdir)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Flatten, BatchNormalization, Permute, TimeDistributed, Dense, Bidirectional, GRU, LSTM\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, Adam, Adadelta, RMSprop\n",
    "\n",
    "img_h = 32\n",
    "\n",
    "# n_class 如果不加1会报错  Saw a non-null label (index >= num_classes - 1) following a null label,\n",
    "n_class = len(alphabet)+1\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "# def ctc_lambda_func(args):\n",
    "#     y_pred, labels, input_length, label_length = args\n",
    "#     # 注意这里若使用y_pred会导致sequence_length（0）<= X.\n",
    "#     # 注意理解sequence_length(0)这个东西  这里是32  因为第41句中的img_w//poolsize（2）是sequence_length（0）\n",
    "#     y_pred = y_pred[:, :, :]\n",
    "#     # 这里labels是实际的标签，y_pred是预测出来的标签，input_length是预测标签的长度，label_length是实际标签的长度\n",
    "#     return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def crnn_network(height=img_h, nclass=n_class):\n",
    "    '''\n",
    "    cnn + rnn + ctc model !!!\n",
    "    :param height:\n",
    "    :param nclass:\n",
    "    :return:\n",
    "    '''\n",
    "    input = Input(shape=(height, None, 1), name='the_input')\n",
    "    # CNN\n",
    "    m = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', name='conv1')(input)\n",
    "    m = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool1')(m)\n",
    "    m = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', name='conv2')(m)\n",
    "    m = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool2')(m)\n",
    "    m = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', name='conv3')(m)\n",
    "    m = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', name='conv4')(m)\n",
    "\n",
    "    m = ZeroPadding2D(padding=(0, 1))(m)\n",
    "    m = MaxPooling2D(pool_size=(2, 2), strides=(2, 1), padding='valid', name='pool3')(m)\n",
    "\n",
    "    m = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='conv5')(m)\n",
    "    m = BatchNormalization(axis=3)(m)\n",
    "    m = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='conv6')(m)\n",
    "    m = BatchNormalization(axis=3)(m)\n",
    "#     m = ZeroPadding2D(padding=(0, 1))(m)\n",
    "    m = MaxPooling2D(pool_size=(2, 2), strides=(2, 1), padding='valid', name='pool4')(m)\n",
    "#     m = Conv2D(512, kernel_size=(2, 2), activation='relu', padding='valid', name='conv7')(m)\n",
    "\n",
    "    # m的输出维度为(h, w, c) -> (1, w/4, 512) 转换 (w, b, c) = (seq_len, batch, input_size)\n",
    "    m = Permute((2, 1, 3), name='permute')(m)\n",
    "    m = TimeDistributed(Flatten(), name='timedistrib')(m)\n",
    "\n",
    "    # RNN \n",
    "    # LSTM GRU 为何参数不一样？\n",
    "    m = Bidirectional(GRU(64, return_sequences=True), name='blstm1')(m)\n",
    "    m = Dense(64, name='blstm1_out', activation='linear')(m)\n",
    "    m = Bidirectional(GRU(64, return_sequences=True), name='blstm2')(m)\n",
    "    \n",
    "    y_pred = Dense(nclass, name='blstm2_out', activation='softmax')(m)\n",
    "\n",
    "    basemodel = Model(inputs=input, outputs=y_pred)\n",
    "    #basemodel.summary()\n",
    "    \n",
    "    # max_len\n",
    "    max_len = None # None  12\n",
    "    labels = Input(name='the_labels', shape=[max_len], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[input, labels, input_length, label_length], outputs=[loss_out])\n",
    "\n",
    "    # sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "    # model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd, metrics=['accuracy'])\n",
    "    # model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=\"adadelta\", metrics=['accuracy'])\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam', metrics=['accuracy'])\n",
    "#     model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model, basemodel\n",
    "\n",
    "def predict(img_path, model):\n",
    "    \"\"\"\n",
    "    输入图片，输出keras模型的识别结果\n",
    "    :param img_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path)\n",
    "    img = img.convert('L')\n",
    "\n",
    "    scale = img.size[1] * 1.0 / 32\n",
    "    w = int(img.size[0] / scale)\n",
    "    img = img.resize((w, 32), Image.BILINEAR)\n",
    "    img = np.array(img).astype(np.float32) / 255.0 - 0.5\n",
    "    X = img.reshape((32, w, 1))\n",
    "    X = np.array([X])\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    y_pred = y_pred[:, :, :]\n",
    "\n",
    "    out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[0]) * y_pred.shape[1], )[0][0])[:, :]\n",
    "    out_s = u''.join([char[x] for x in out[0]])\n",
    "\n",
    "    return out_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_65\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 32, None, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, None, 16) 160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 16, None, 16) 0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 16, None, 16) 2320        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 8, None, 16)  0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 8, None, 32)  4640        pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 8, None, 32)  9248        conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPadding2 (None, 8, None, 32)  0           conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 4, None, 32)  0           zero_padding2d_25[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 4, None, 64)  18496       pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 4, None, 64)  256         conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 4, None, 64)  36928       batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 4, None, 64)  256         conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)            (None, 2, None, 64)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, None, 2, 64)  0           pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "timedistrib (TimeDistributed)   (None, None, 128)    0           permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "blstm1 (Bidirectional)          (None, None, 128)    74112       timedistrib[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "blstm1_out (Dense)              (None, None, 64)     8256        blstm1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "blstm2 (Bidirectional)          (None, None, 128)    49536       blstm1_out[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "blstm2_out (Dense)              (None, None, 12)     1548        blstm2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           blstm2_out[0][0]                 \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 205,756\n",
      "Trainable params: 205,500\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, basemodel = crnn_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600\n",
      "8130\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.4296 - accuracy: 0.8765 - val_loss: 1.9906 - val_accuracy: 0.4325\n",
      "\n",
      "Epoch 00001: saving model to base_model.h5\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.3903 - accuracy: 0.8856 - val_loss: 3.1909 - val_accuracy: 0.4863\n",
      "\n",
      "Epoch 00002: saving model to base_model.h5\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 67s 133ms/step - loss: 0.3644 - accuracy: 0.9018 - val_loss: 0.6526 - val_accuracy: 0.5475\n",
      "\n",
      "Epoch 00003: saving model to base_model.h5\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 67s 133ms/step - loss: 0.3520 - accuracy: 0.9078 - val_loss: 2.6449 - val_accuracy: 0.5150\n",
      "\n",
      "Epoch 00004: saving model to base_model.h5\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 67s 133ms/step - loss: 0.3024 - accuracy: 0.9201 - val_loss: 2.6559 - val_accuracy: 0.4613\n",
      "\n",
      "Epoch 00005: saving model to base_model.h5\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "save_path = 'base_model.h5'\n",
    "\n",
    "if os.path.exists(save_path):\n",
    "    try:\n",
    "        model.load_weights(save_path)\n",
    "    except Exception as e:\n",
    "        print('Load weights raise exception.')\n",
    "        print(e)\n",
    "\n",
    "checkpoint = ModelCheckpoint(save_path, \n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_weights_only=True)\n",
    "base_path = 'images/'\n",
    "train_folder = '/Users/liuliangjun/Downloads/images/train/'\n",
    "vaild_folder = '/Users/liuliangjun/Downloads/images/vaild/'\n",
    "max_len = 16\n",
    "model.fit_generator(generator=loadpic(train_folder, 16, 16, 2**4),\n",
    "                    steps_per_epoch=500, \n",
    "                    epochs=5,\n",
    "                    callbacks=[checkpoint],\n",
    "                    validation_data=loadpic(vaild_folder, 16, 16, 2**4),\n",
    "                    validation_steps=50,\n",
    "                    )\n",
    "\n",
    "\n",
    "basemodel.save('predict_model.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "my_model=load_model('predict_model.h5', custom_objects = {'<lambda>': lambda y_true, y_pred: y_pred})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_path, model):\n",
    "    \"\"\"\n",
    "    输入图片，输出keras模型的识别结果\n",
    "    :param img_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path)\n",
    "    img = img.convert('L')\n",
    "\n",
    "    scale = img.size[1] * 1.0 / 32\n",
    "    w = int(img.size[0] / scale)\n",
    "    img = img.resize((w, 32), Image.BILINEAR)\n",
    "    img = np.array(img).astype(np.float32) / 255.0 - 0.5\n",
    "    X = img.reshape((32, w, 1))\n",
    "#     print(X.shape)\n",
    "    X = np.array([X])\n",
    "    \n",
    "#     print(X.shape)\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    y_pred = y_pred[:, :, :]\n",
    "\n",
    "    out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[0]) * y_pred.shape[1], )[0][0])[:, :]\n",
    "    out_s = u''.join([char[x] for x in out[0]])\n",
    "\n",
    "    return out_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'char' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-f937dd3994c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/liuliangjun/Downloads/images/3_403 9.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-193-ee296b66db96>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(img_path, model)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctc_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mout_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-193-ee296b66db96>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctc_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mout_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'char' is not defined"
     ]
    }
   ],
   "source": [
    "predict('/Users/liuliangjun/Downloads/images/3_403 9.png', my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import cv2\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def labels_to_text(labels):\n",
    "    ret = []\n",
    "    for c in labels:\n",
    "        if c == len(alphabet):  # CTC Blank\n",
    "            ret.append(\"\")\n",
    "        else:\n",
    "            ret.append(alphabet[c])\n",
    "    return \"\".join(ret)\n",
    "\n",
    "def decode_predict_ctc(out, top_paths = 1):\n",
    "    results = []\n",
    "    beam_width = 5\n",
    "    if beam_width < top_paths:\n",
    "      beam_width = top_paths\n",
    "    for i in range(top_paths):\n",
    "      lables = K.get_value(K.ctc_decode(out, input_length=np.ones(out.shape[0])*out.shape[1],\n",
    "                           greedy=False, beam_width=beam_width, top_paths=top_paths)[0][i])[0]\n",
    "      text = labels_to_text(lables)\n",
    "      results.append(text)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 124, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['61978']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict('/Users/liuliangjun/Downloads/images/3_403 9.png', my_model)\n",
    "\n",
    "img=cv2.imread('/Users/liuliangjun/Downloads/images/1_61978.png', 0)\n",
    "img=cv2.resize(img,(124,32))\n",
    "img=img_to_array(img)\n",
    "img=np.array(img,dtype='float')/255.0 - 0.5\n",
    "img=np.expand_dims(img, axis=0)\n",
    "# img=img.swapaxes(1,2)   \n",
    "print(img.shape)\n",
    "top_pred_texts = decode_predict_ctc(my_model.predict(img))\n",
    "top_pred_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nums: 10, name: name\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'afa 1, 90'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = 10\n",
    "name = 'name'\n",
    "print(f'nums: {nums}, name: {name}')\n",
    "'afa {}, {}'.format(10-9, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
