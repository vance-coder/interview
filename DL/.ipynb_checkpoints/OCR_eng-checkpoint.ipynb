{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trdg.generators import (\n",
    "    GeneratorFromDict,\n",
    "    GeneratorFromRandom,\n",
    "    GeneratorFromStrings,\n",
    "    GeneratorFromWikipedia,\n",
    ")\n",
    "from random import sample\n",
    "from itertools import combinations, permutations\n",
    "\n",
    "\n",
    "folder = '/Users/liuliangjun/Downloads/images/train'\n",
    "\n",
    "ss = '0123456789 '\n",
    "_len_8 = [i for i in map(lambda x: ''.join(x), permutations(ss, 8))]\n",
    "_len_7 = [i for i in map(lambda x: ''.join(x), permutations(ss, 7))]\n",
    "_len_7 = [i for i in map(lambda x: ''.join(x), permutations(ss, 7))]\n",
    "_len_6 = [i for i in map(lambda x: ''.join(x), permutations(ss, 6))]\n",
    "_len_5 = [i for i in map(lambda x: ''.join(x), permutations(ss, 5))]\n",
    "_len_4 = [i for i in map(lambda x: ''.join(x), permutations(ss, 4))]\n",
    "_len_3 = [i for i in map(lambda x: ''.join(x), permutations(ss, 3))]\n",
    "_len_2 = [i for i in map(lambda x: ''.join(x), permutations(ss, 2))]\n",
    "\n",
    "\n",
    "lst = [*sample(_len_6, 200), *sample(_len_7, 200), *sample(_len_8, 200)]\n",
    "# lst = [*_len_2, *sample(_len_3, 300), *sample(_len_4, 500), *sample(_len_6, 800), *sample(_len_7, 1000)]\n",
    "# lst = sample(_len_5, 20)\n",
    "lst = [i.strip() for i in lst]\n",
    "print(len(lst))\n",
    "\n",
    "\n",
    "generator = GeneratorFromStrings(lst, width=250, count=len(lst)*3)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for img, lbl in generator:\n",
    "    img.save(os.path.join(folder, f'{count}_{lbl}.png'))\n",
    "    count += 1\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alphabet = u'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ~!@#$%^&*?-_+=()[]{}/|\\<>,.;:\\'\" '\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "len(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def image_preporcess(image, target_size):\n",
    "\n",
    "    # resize 尺寸\n",
    "    ih, iw = target_size\n",
    "    # 原始图片尺寸\n",
    "    h,  w = image.shape\n",
    "\n",
    "    # 计算缩放后图片尺寸\n",
    "    scale = min(iw/w, ih/h)\n",
    "    nw, nh = int(scale * w), int(scale * h)\n",
    "    image_resized = cv2.resize(image, (nw, nh))\n",
    "\n",
    "    # 创建一张画布，画布的尺寸就是目标尺寸\n",
    "    # fill_value=120为灰色画布\n",
    "    image_paded = np.full(shape=[ih, iw], fill_value=255)\n",
    "    dw, dh = (iw - nw) // 2, (ih-nh) // 2\n",
    "\n",
    "    # 将缩放后的图片放在画布中央\n",
    "    image_paded[dh:nh+dh, dw:nw+dw] = image_resized\n",
    "    \n",
    "#     # 将图片转为灰度图\n",
    "#     img_gray = cv2.cvtColor(image_paded,cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # 归一化处理\n",
    "#     image_paded = image_paded / 255.\n",
    "\n",
    "    return image_paded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import cv2\n",
    "import random\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "def text_to_labels(text,alphabet):\n",
    "    ret = []\n",
    "    for char in text:\n",
    "        ret.append(alphabet.find(char))\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def loadpic(path,batchSize,absolute_max_string_len,downsample_factor):\n",
    "    imgPaths=list(paths.list_images(path))\n",
    "    random.shuffle(imgPaths) \n",
    "    print(len(imgPaths))\n",
    "    random.seed(20)\n",
    "\n",
    "    while 1:\n",
    "        x_batch=[]#图片\n",
    "        flag = False\n",
    "        y_batch=np.ones([batchSize, absolute_max_string_len]) * -1 # 图片标签变成编码\n",
    "        input_length = np.zeros([batchSize, 1]) # 图片下采样后进入GRN的尺寸\n",
    "        label_length=np.zeros([batchSize, 1]) # 图片中字符的长度\n",
    "        labels_batch=[] # 图片的真是标签 字符串\n",
    "        for i in range(batchSize):\n",
    "\n",
    "            imgpath=imgPaths[random.randint(0,len(imgPaths)-1)]\n",
    "            # print(imgpath)\n",
    "            try:\n",
    "                img=cv2.imread(imgpath,0)\n",
    "#                 img=cv2.resize(img,(186,32))\n",
    "            except:\n",
    "                print(imgpath)\n",
    "                flag = True\n",
    "                break\n",
    "            \n",
    "            # cv2.imshow(\"ig\",img)\n",
    "            # cv2.waitKey(30)\n",
    "            img = image_preporcess(img, (32,224))\n",
    "            img=img_to_array(img)\n",
    "#             print(img.shape)\n",
    "\n",
    "            x_batch.append(img)\n",
    "            \n",
    "            input_length[i]=np.array(img).shape[1]//downsample_factor\n",
    "\n",
    "            # imgname=imgpath[imgpath.rindex('\\\\')+1:imgpath.rindex('.')]\n",
    "            imgname=imgpath.split('_')[-1].split('.')[0]\n",
    "#             print(len(imgname))\n",
    "            labels_batch.append(imgname)\n",
    "\n",
    "            label_length[i]=len(imgname)\n",
    "\n",
    "            y_batch[i,0:len(imgname)]=text_to_labels(imgname, alphabet)\n",
    "\n",
    "        if flag:\n",
    "            flag = False\n",
    "            continue\n",
    "\n",
    "        x_batch = np.array(x_batch, dtype=\"float\") / 255.0 - 0.5\n",
    "#         x_batch= x_batch.swapaxes(1,2)\n",
    "#         print(y_batch)\n",
    "#         print(input_length)\n",
    "#         print(label_length)\n",
    "        inputs = {'the_input': x_batch,\n",
    "                  'the_labels': y_batch,\n",
    "                  'input_length': input_length,\n",
    "                  'label_length': label_length,\n",
    "                  'source_str': labels_batch  # used for visualization only # 可视化使用\n",
    "                  }\n",
    "        outputs = {'ctc': np.zeros([batchSize])}  \n",
    "        yield (inputs,outputs)\n",
    "        \n",
    "# https://github.com/felixBrave/ocr_chinese/blob/master/crnn/net/training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 是\n",
    "\n",
    "import os,sys\n",
    "# parentdir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "# sys.path.append(parentdir)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Flatten, BatchNormalization, Permute, TimeDistributed, Dense, Bidirectional, GRU, LSTM\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, Adam, Adadelta, RMSprop\n",
    "\n",
    "img_h = 32\n",
    "\n",
    "# n_class 如果不加1会报错  Saw a non-null label (index >= num_classes - 1) following a null label,\n",
    "n_class = len(alphabet) + 1\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "# def ctc_lambda_func(args):\n",
    "#     y_pred, labels, input_length, label_length = args\n",
    "#     # 注意这里若使用y_pred会导致sequence_length（0）<= X.\n",
    "#     # 注意理解sequence_length(0)这个东西  这里是32  因为第41句中的img_w//poolsize（2）是sequence_length（0）\n",
    "#     y_pred = y_pred[:, :, :]\n",
    "#     # 这里labels是实际的标签，y_pred是预测出来的标签，input_length是预测标签的长度，label_length是实际标签的长度\n",
    "#     return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def crnn_network(height=img_h, nclass=n_class):\n",
    "    '''\n",
    "    cnn + rnn + ctc model !!!\n",
    "    :param height:\n",
    "    :param nclass:\n",
    "    :return:\n",
    "    '''\n",
    "    input = Input(shape=(height, None, 1), name='the_input')\n",
    "    # CNN\n",
    "    m = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', name='conv1')(input)\n",
    "    m = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool1')(m)\n",
    "    m = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', name='conv2')(m)\n",
    "    m = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool2')(m)\n",
    "    m = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='conv3')(m)\n",
    "    m = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='conv4')(m)\n",
    "\n",
    "    m = ZeroPadding2D(padding=(0, 1))(m)\n",
    "    m = MaxPooling2D(pool_size=(2, 2), strides=(2, 1), padding='valid', name='pool3')(m)\n",
    "\n",
    "    m = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', name='conv5')(m)\n",
    "    m = BatchNormalization(axis=3)(m)\n",
    "    m = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', name='conv6')(m)\n",
    "    m = BatchNormalization(axis=3)(m)\n",
    "#     m = ZeroPadding2D(padding=(0, 1))(m)\n",
    "    m = MaxPooling2D(pool_size=(2, 2), strides=(2, 1), padding='valid', name='pool4')(m)\n",
    "#     m = Conv2D(512, kernel_size=(2, 2), activation='relu', padding='valid', name='conv7')(m)\n",
    "\n",
    "    # m的输出维度为(h, w, c) -> (1, w/4, 512) 转换 (w, b, c) = (seq_len, batch, input_size)\n",
    "    m = Permute((2, 1, 3), name='permute')(m)\n",
    "    m = TimeDistributed(Flatten(), name='timedistrib')(m)\n",
    "\n",
    "    # RNN \n",
    "    m = Bidirectional(GRU(128, return_sequences=True), name='blstm1')(m)\n",
    "    m = Dense(128, name='blstm1_out', activation='linear')(m)\n",
    "    m = Bidirectional(GRU(128, return_sequences=True), name='blstm2')(m)\n",
    "    \n",
    "    y_pred = Dense(nclass, name='blstm2_out', activation='softmax')(m)\n",
    "\n",
    "    basemodel = Model(inputs=input, outputs=y_pred)\n",
    "    #basemodel.summary()\n",
    "    \n",
    "    # max_len\n",
    "    max_len = None # None  12\n",
    "    labels = Input(name='the_labels', shape=[max_len], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(inputs=[input, labels, input_length, label_length], outputs=[loss_out])\n",
    "\n",
    "    # sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "    # model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd, metrics=['accuracy'])\n",
    "    # model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=\"adadelta\", metrics=['accuracy'])\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam', metrics=['accuracy'])\n",
    "#     model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model, basemodel\n",
    "\n",
    "def predict(img_path, model):\n",
    "    \"\"\"\n",
    "    输入图片，输出keras模型的识别结果\n",
    "    :param img_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path)\n",
    "    img = img.convert('L')\n",
    "\n",
    "    scale = img.size[1] * 1.0 / 32\n",
    "    w = int(img.size[0] / scale)\n",
    "    img = img.resize((w, 32), Image.BILINEAR)\n",
    "    img = np.array(img).astype(np.float32) / 255.0 - 0.5\n",
    "    X = img.reshape((32, w, 1))\n",
    "    X = np.array([X])\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    y_pred = y_pred[:, :, :]\n",
    "\n",
    "    out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[0]) * y_pred.shape[1], )[0][0])[:, :]\n",
    "    out_s = u''.join([char[x] for x in out[0]])\n",
    "\n",
    "    return out_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 32, None, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, None, 32) 320         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 16, None, 32) 0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 16, None, 32) 9248        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 8, None, 32)  0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 8, None, 64)  18496       pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 8, None, 64)  36928       conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 8, None, 64)  0           conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 4, None, 64)  0           zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 4, None, 128) 73856       pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 4, None, 128) 512         conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 4, None, 128) 147584      batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 4, None, 128) 512         conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)            (None, 2, None, 128) 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, None, 2, 128) 0           pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "timedistrib (TimeDistributed)   (None, None, 256)    0           permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "blstm1 (Bidirectional)          (None, None, 256)    295680      timedistrib[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "blstm1_out (Dense)              (None, None, 128)    32896       blstm1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "blstm2 (Bidirectional)          (None, None, 256)    197376      blstm1_out[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "blstm2_out (Dense)              (None, None, 28)     7196        blstm2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           blstm2_out[0][0]                 \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 820,604\n",
      "Trainable params: 820,092\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, basemodel = crnn_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "0\n",
      "10516\n",
      "contextual [2, 14, 13, 19, 4, 23, 19, 20, 0, 11]\n",
      "pspp [15, 18, 15, 15]\n",
      "note it [13, 14, 19, 4, 26, 8, 19]\n",
      "by donating [1, 24, 26, 3, 14, 13, 0, 19, 8, 13, 6]\n",
      "use my [20, 18, 4, 26, 12, 24]\n",
      "an ample [0, 13, 26, 0, 12, 15, 11, 4]\n",
      "increases were [8, 13, 2, 17, 4, 0, 18, 4, 18, 26, 22, 4, 17, 4]\n",
      "unapologetic [20, 13, 0, 15, 14, 11, 14, 6, 4, 19, 8, 2]\n",
      "benefits through [1, 4, 13, 4, 5, 8, 19, 18, 26, 19, 7, 17, 14, 20, 6, 7]\n",
      "grunwald [6, 17, 20, 13, 22, 0, 11, 3]\n",
      "making any [12, 0, 10, 8, 13, 6, 26, 0, 13, 24]\n",
      "its growth [8, 19, 18, 26, 6, 17, 14, 22, 19, 7]\n",
      "edit [4, 3, 8, 19]\n",
      "never returned [13, 4, 21, 4, 17, 26, 17, 4, 19, 20, 17, 13, 4, 3]\n",
      "soelden [18, 14, 4, 11, 3, 4, 13]\n",
      "signposts [18, 8, 6, 13, 15, 14, 18, 19, 18]\n",
      "categorized [2, 0, 19, 4, 6, 14, 17, 8, 25, 4, 3]\n",
      "strain [18, 19, 17, 0, 8, 13]\n",
      "may immediately [12, 0, 24, 26, 8, 12, 12, 4, 3, 8, 0, 19, 4, 11, 24]\n",
      "windfall [22, 8, 13, 3, 5, 0, 11, 11]\n",
      "at major [0, 19, 26, 12, 0, 9, 14, 17]\n",
      "applications is [0, 15, 15, 11, 8, 2, 0, 19, 8, 14, 13, 18, 26, 8, 18]\n",
      "wplug [22, 15, 11, 20, 6]\n",
      "coquitlam [2, 14, 16, 20, 8, 19, 11, 0, 12]\n",
      "  1/300 [..............................] - ETA: 1:42 - loss: 23.6950 - accuracy: 0.0000e+00scrutinised [18, 2, 17, 20, 19, 8, 13, 8, 18, 4, 3]\n",
      "headington [7, 4, 0, 3, 8, 13, 6, 19, 14, 13]\n",
      "  2/300 [..............................] - ETA: 1:16 - loss: 24.8626 - accuracy: 0.0000e+00mortgage online [12, 14, 17, 19, 6, 0, 6, 4, 26, 14, 13, 11, 8, 13, 4]\n",
      "So today [-1, 14, 26, 19, 14, 3, 0, 24]\n",
      "  3/300 [..............................] - ETA: 1:09 - loss: 23.9989 - accuracy: 0.0000e+00gsasl [6, 18, 0, 18, 11]\n",
      "applicant in [0, 15, 15, 11, 8, 2, 0, 13, 19, 26, 8, 13]\n",
      "  4/300 [..............................] - ETA: 1:06 - loss: 28.6327 - accuracy: 0.0000e+00states that [18, 19, 0, 19, 4, 18, 26, 19, 7, 0, 19]\n",
      "deconstructed [3, 4, 2, 14, 13, 18, 19, 17, 20, 2, 19, 4, 3]\n",
      "  5/300 [..............................] - ETA: 1:03 - loss: 31.0702 - accuracy: 0.0000e+00Rare and [-1, 0, 17, 4, 26, 0, 13, 3]\n",
      "amstrad [0, 12, 18, 19, 17, 0, 3]\n",
      "  6/300 [..............................] - ETA: 1:04 - loss: 31.3365 - accuracy: 0.0000e+00consistency and [2, 14, 13, 18, 8, 18, 19, 4, 13, 2, 24, 26, 0, 13, 3]\n",
      "audiobahn [0, 20, 3, 8, 14, 1, 0, 7, 13]\n",
      "  7/300 [..............................] - ETA: 1:06 - loss: 31.2082 - accuracy: 0.0000e+00specific training [18, 15, 4, 2, 8, 5, 8, 2, 26, 19, 17, 0, 8, 13, 8, 13, 6]\n",
      "hustle [7, 20, 18, 19, 11, 4]\n",
      "  8/300 [..............................] - ETA: 1:04 - loss: 30.4078 - accuracy: 0.0000e+00prongs [15, 17, 14, 13, 6, 18]\n",
      "media needs [12, 4, 3, 8, 0, 26, 13, 4, 4, 3, 18]\n",
      "  9/300 [..............................] - ETA: 1:02 - loss: 29.8834 - accuracy: 0.0000e+00combo [2, 14, 12, 1, 14]\n",
      "Cribs and [-1, 17, 8, 1, 18, 26, 0, 13, 3]\n",
      " 10/300 [>.............................] - ETA: 1:02 - loss: 30.5347 - accuracy: 0.0000e+00things or [19, 7, 8, 13, 6, 18, 26, 14, 17]\n",
      "is factory [8, 18, 26, 5, 0, 2, 19, 14, 17, 24]\n",
      " 11/300 [>.............................] - ETA: 1:04 - loss: 31.0725 - accuracy: 0.0000e+00can detect [2, 0, 13, 26, 3, 4, 19, 4, 2, 19]\n",
      "reveals an [17, 4, 21, 4, 0, 11, 18, 26, 0, 13]\n",
      " 12/300 [>.............................] - ETA: 1:03 - loss: 30.5651 - accuracy: 0.0000e+00mitsumi [12, 8, 19, 18, 20, 12, 8]\n",
      "charities [2, 7, 0, 17, 8, 19, 8, 4, 18]\n",
      " 13/300 [>.............................] - ETA: 1:02 - loss: 30.6048 - accuracy: 0.0000e+00boudreau [1, 14, 20, 3, 17, 4, 0, 20]\n",
      "siig [18, 8, 8, 6]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "All labels must be nonnegative integers, batch: 1 labels: -1,14,26,19,14,3,0,24\n\t [[{{node ctc_10/CTCLoss}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-345-4686195bbb53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloadpic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvaild_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                     )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: All labels must be nonnegative integers, batch: 1 labels: -1,14,26,19,14,3,0,24\n\t [[{{node ctc_10/CTCLoss}}]]"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "save_path = 'base_model.h5'\n",
    "\n",
    "if os.path.exists(save_path):\n",
    "    try:\n",
    "        model.load_weights(save_path)\n",
    "    except Exception as e:\n",
    "        print('Load weights raise exception.')\n",
    "        print(e)\n",
    "\n",
    "checkpoint = ModelCheckpoint(save_path, \n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_weights_only=True)\n",
    "base_path = 'images/'\n",
    "train_folder = '/Users/liuliangjun/Downloads/images/train/'\n",
    "vaild_folder = '/Users/liuliangjun/Downloads/images/vaild/'\n",
    "max_len = 32\n",
    "model.fit_generator(generator=loadpic(train_folder, 2, max_len, 2**3),\n",
    "                    steps_per_epoch=300, \n",
    "                    epochs=5,\n",
    "                    callbacks=[checkpoint],\n",
    "                    validation_data=loadpic(vaild_folder, 2, max_len, 2**3),\n",
    "                    validation_steps=50,\n",
    "                    )\n",
    "\n",
    "\n",
    "basemodel.save('predict_model.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "my_model=load_model('predict_model.h5', custom_objects = {'<lambda>': lambda y_true, y_pred: y_pred})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_path, model):\n",
    "    \"\"\"\n",
    "    输入图片，输出keras模型的识别结果\n",
    "    :param img_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path)\n",
    "    img = img.convert('L')\n",
    "\n",
    "    scale = img.size[1] * 1.0 / 32\n",
    "    w = int(img.size[0] / scale)\n",
    "    img = img.resize((w, 32), Image.BILINEAR)\n",
    "    img = np.array(img).astype(np.float32) / 255.0 - 0.5\n",
    "    X = img.reshape((32, w, 1))\n",
    "#     print(X.shape)\n",
    "    X = np.array([X])\n",
    "    \n",
    "#     print(X.shape)\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    y_pred = y_pred[:, :, :]\n",
    "\n",
    "    out = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[0]) * y_pred.shape[1], )[0][0])[:, :]\n",
    "    out_s = u''.join([char[x] for x in out[0]])\n",
    "\n",
    "    return out_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict('/Users/liuliangjun/Downloads/images/3_403 9.png', my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import cv2\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def labels_to_text(labels):\n",
    "    ret = []\n",
    "    for c in labels:\n",
    "        if c == len(alphabet):  # CTC Blank\n",
    "            ret.append(\"\")\n",
    "        else:\n",
    "            ret.append(alphabet[c])\n",
    "    return \"\".join(ret)\n",
    "\n",
    "def decode_predict_ctc(out, top_paths = 1):\n",
    "    results = []\n",
    "    beam_width = 5\n",
    "    if beam_width < top_paths:\n",
    "      beam_width = top_paths\n",
    "    for i in range(top_paths):\n",
    "      lables = K.get_value(K.ctc_decode(out, input_length=np.ones(out.shape[0])*out.shape[1],\n",
    "                           greedy=False, beam_width=beam_width, top_paths=top_paths)[0][i])[0]\n",
    "      text = labels_to_text(lables)\n",
    "      results.append(text)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 124, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['9 038']"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict('/Users/liuliangjun/Downloads/images/3_403 9.png', my_model)\n",
    "\n",
    "img=cv2.imread('/Users/liuliangjun/Downloads/images/14_9 038.png', 0)\n",
    "img=cv2.resize(img,(124,32))\n",
    "img=img_to_array(img)\n",
    "img=np.array(img,dtype='float')/255.0 - 0.5\n",
    "img=np.expand_dims(img, axis=0)\n",
    "# img=img.swapaxes(1,2)   \n",
    "print(img.shape)\n",
    "top_pred_texts = decode_predict_ctc(my_model.predict(img))\n",
    "top_pred_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from random import shuffle\n",
    "import os\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "regex = r'^[a-zA-Z\\d ]+$'\n",
    "text_max_len = 32  # 最长匹配字符串\n",
    "\n",
    "\n",
    "def download_word_list():\n",
    "    # 下载单词列表文件，并解压\n",
    "    file_path = get_file('wordlists.tgz', origin='http://www.mythic-ai.com/datasets/wordlists.tgz', untar=True)\n",
    "    file_dir = os.path.dirname(file_path)\n",
    "\n",
    "    # 单词文件 86498行 （一行一个单词或字母）\n",
    "    monogram_file = os.path.join(file_dir, 'wordlist_mono_clean.txt')\n",
    "\n",
    "    # 词组文件 83738行（该文件会包含一些符号）\n",
    "    bigram_file = os.path.join(file_dir, 'wordlist_bi_clean.txt')\n",
    "\n",
    "    return monogram_file, bigram_file\n",
    "\n",
    "\n",
    "def is_valid_str(in_str):\n",
    "    search = re.compile(regex, re.UNICODE).search\n",
    "    return bool(search(in_str))\n",
    "\n",
    "\n",
    "def get_word_list(file_path):\n",
    "    with open(file_path) as fp:\n",
    "        row_list = [row.strip() for row in fp]\n",
    "        return [row for row in row_list if is_valid_str(row) and len(row) <= text_max_len]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_image():\n",
    "    folder = '/Users/liuliangjun/Downloads/images/valid'\n",
    "    monogram_file, bigram_file = download_word_list()\n",
    "    mono_words = get_word_list(monogram_file)\n",
    "    bi_words = get_word_list(bigram_file)\n",
    "\n",
    "    word_list = mono_words + bi_words\n",
    "\n",
    "    # 打乱单词列表\n",
    "    shuffle(word_list)\n",
    "    \n",
    "    word_list = word_list[:1000]\n",
    "    for idx, word in enumerate(word_list):\n",
    "        try:\n",
    "            img = draw_img(word)\n",
    "            img.save(os.path.join(folder, f'{idx}_{word}.png'))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "create_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('herzegovinabulgariacroatiaczech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=228x32 at 0x14C4BEB00>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "def draw_img(strs):\n",
    "    bg_idx = random.randint(1, 21)\n",
    "    bg_img = f'/Users/liuliangjun/Downloads/images/background{bg_idx}.png'\n",
    "    \n",
    "    img = Image.open(bg_img)\n",
    "    img = img.convert('L')\n",
    "    \n",
    "    pixels = np.array(img).flatten()\n",
    "    avg_pixels = sum(pixels)/len(pixels)\n",
    "    \n",
    "    w, h = img.size\n",
    "    # display(img)\n",
    "    \n",
    "    font_list = ['SourceCodePro-Regular.ttf',\n",
    "                'SourceCodePro-Bold.ttf',\n",
    "                'Arial Unicode.ttf',\n",
    "                'Menlo.ttc',\n",
    "                'STHeiti Light.ttc',\n",
    "                'STHeiti Medium.ttc']\n",
    "    \n",
    "    font = random.choice(font_list)\n",
    "    font_size = random.randint(12, 18)\n",
    "\n",
    "    font = ImageFont.truetype(f'/System/Library/Fonts/{font}', font_size)\n",
    "    \n",
    "    imgage_draw = ImageDraw.Draw(img)\n",
    "    w_, h_ = imgage_draw.textsize(strs, font=font)\n",
    "    \n",
    "    if w_ >= w:\n",
    "        font = ImageFont.truetype(f'/System/Library/Fonts/{font}', font_size-2)\n",
    "    \n",
    "    # spacing 行间的像素数量\n",
    "    if avg_pixels > 127:\n",
    "        color = random.randint(0, 100)\n",
    "    else:\n",
    "        color = random.randint(180, 255)\n",
    "    imgage_draw.text(((w-w_)/2, (h-h_)/2), strs, fill=color, font=font)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "draw_img('herzegovinabulgariacroatiaczech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('everyone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method text in module PIL.ImageDraw:\n",
      "\n",
      "text(xy, text, fill=None, font=None, anchor=None, spacing=4, align='left', direction=None, features=None, language=None, stroke_width=0, stroke_fill=None, *args, **kwargs) method of PIL.ImageDraw.ImageDraw instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ImageDraw.Draw(img).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217, 18)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ImageDraw.Draw(img).textsize('My everyone hello world', font=font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function truetype in module PIL.ImageFont:\n",
      "\n",
      "truetype(font=None, size=10, index=0, encoding='', layout_engine=None)\n",
      "    Load a TrueType or OpenType font from a file or file-like object,\n",
      "    and create a font object.\n",
      "    This function loads a font object from the given file or file-like\n",
      "    object, and creates a font object for a font of the given size.\n",
      "    \n",
      "    Pillow uses FreeType to open font files. If you are opening many fonts\n",
      "    simultaneously on Windows, be aware that Windows limits the number of files\n",
      "    that can be open in C at once to 512. If you approach that limit, an\n",
      "    ``OSError`` may be thrown, reporting that FreeType \"cannot open resource\".\n",
      "    \n",
      "    This function requires the _imagingft service.\n",
      "    \n",
      "    :param font: A filename or file-like object containing a TrueType font.\n",
      "                 If the file is not found in this filename, the loader may also\n",
      "                 search in other directories, such as the :file:`fonts/`\n",
      "                 directory on Windows or :file:`/Library/Fonts/`,\n",
      "                 :file:`/System/Library/Fonts/` and :file:`~/Library/Fonts/` on\n",
      "                 macOS.\n",
      "    \n",
      "    :param size: The requested size, in points.\n",
      "    :param index: Which font face to load (default is first available face).\n",
      "    :param encoding: Which font encoding to use (default is Unicode). Possible\n",
      "                     encodings include (see the FreeType documentation for more\n",
      "                     information):\n",
      "    \n",
      "                     * \"unic\" (Unicode)\n",
      "                     * \"symb\" (Microsoft Symbol)\n",
      "                     * \"ADOB\" (Adobe Standard)\n",
      "                     * \"ADBE\" (Adobe Expert)\n",
      "                     * \"ADBC\" (Adobe Custom)\n",
      "                     * \"armn\" (Apple Roman)\n",
      "                     * \"sjis\" (Shift JIS)\n",
      "                     * \"gb  \" (PRC)\n",
      "                     * \"big5\"\n",
      "                     * \"wans\" (Extended Wansung)\n",
      "                     * \"joha\" (Johab)\n",
      "                     * \"lat1\" (Latin-1)\n",
      "    \n",
      "                     This specifies the character set to use. It does not alter the\n",
      "                     encoding of any text provided in subsequent operations.\n",
      "    :param layout_engine: Which layout engine to use, if available:\n",
      "                     `ImageFont.LAYOUT_BASIC` or `ImageFont.LAYOUT_RAQM`.\n",
      "    :return: A font object.\n",
      "    :exception IOError: If the file could not be read.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ImageFont.truetype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
